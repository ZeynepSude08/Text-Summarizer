{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec3094b6-a728-47f2-8fa4-92b692e373d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.52.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1605e864-1747-4131-b717-61faabc8fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "\n",
    "# Tokenizer ve model (from_tf yazma!)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f5ec69a-00ad-43c1-bdd1-6ec0efe4eb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.7.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dc63baf-6489-4ef3-b3b9-bd4e22cbccd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ea6c897-b3e7-4759-ba3e-bf7bff27731a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ÖZET -----\n",
      "2004 film takes place in iraqi orphan community, fall saddam hussein. main character satellite, boy manages takes care orphans. Main source income unearthing landmines reselling them. end film, agrin murdered child drowning pond, commits suicide.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Model ve tokenizer'ı yükle\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Özetlenecek metni gir\n",
    "with open(\"/Metinler/turtles_summary_essay.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize et (BART için 1024 token sınırı var)\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Özet üret\n",
    "summary_ids = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Tokenları yazıya çevir\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Yazdır\n",
    "print(\"----- ÖZET -----\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17208a58-1b30-42bd-8876-2170ffc12280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan aygıt: GPU\n",
      "Özet kaydedildi: essay_1_summary.txt\n",
      "Özet kaydedildi: essay_10_summary.txt\n",
      "Özet kaydedildi: essay_100_summary.txt\n",
      "Özet kaydedildi: essay_1000_summary.txt\n",
      "Özet kaydedildi: essay_1001_summary.txt\n",
      "Özet kaydedildi: essay_1002_summary.txt\n",
      "Özet kaydedildi: essay_1003_summary.txt\n",
      "Özet kaydedildi: essay_1004_summary.txt\n",
      "Özet kaydedildi: essay_1005_summary.txt\n",
      "Özet kaydedildi: essay_1006_summary.txt\n",
      "Özet kaydedildi: essay_1007_summary.txt\n",
      "Özet kaydedildi: essay_1008_summary.txt\n",
      "Özet kaydedildi: essay_1009_summary.txt\n",
      "Özet kaydedildi: essay_101_summary.txt\n",
      "Özet kaydedildi: essay_1010_summary.txt\n",
      "Özet kaydedildi: essay_1011_summary.txt\n",
      "Özet kaydedildi: essay_1012_summary.txt\n",
      "Özet kaydedildi: essay_1013_summary.txt\n",
      "Özet kaydedildi: essay_1014_summary.txt\n",
      "Özet kaydedildi: essay_1015_summary.txt\n",
      "Özet kaydedildi: essay_1016_summary.txt\n",
      "Özet kaydedildi: essay_1017_summary.txt\n",
      "Özet kaydedildi: essay_1018_summary.txt\n",
      "Özet kaydedildi: essay_1019_summary.txt\n",
      "Özet kaydedildi: essay_102_summary.txt\n",
      "Özet kaydedildi: essay_1020_summary.txt\n",
      "Özet kaydedildi: essay_1021_summary.txt\n",
      "Özet kaydedildi: essay_1022_summary.txt\n",
      "Özet kaydedildi: essay_1023_summary.txt\n",
      "Özet kaydedildi: essay_1024_summary.txt\n",
      "Özet kaydedildi: essay_1025_summary.txt\n",
      "Özet kaydedildi: essay_1026_summary.txt\n",
      "Özet kaydedildi: essay_1027_summary.txt\n",
      "Özet kaydedildi: essay_1028_summary.txt\n",
      "Özet kaydedildi: essay_1029_summary.txt\n",
      "Özet kaydedildi: essay_103_summary.txt\n",
      "Özet kaydedildi: essay_1030_summary.txt\n",
      "Özet kaydedildi: essay_1031_summary.txt\n",
      "Özet kaydedildi: essay_1032_summary.txt\n",
      "Özet kaydedildi: essay_1033_summary.txt\n",
      "Özet kaydedildi: essay_1034_summary.txt\n",
      "Özet kaydedildi: essay_1035_summary.txt\n",
      "Özet kaydedildi: essay_1036_summary.txt\n",
      "Özet kaydedildi: essay_1037_summary.txt\n",
      "Özet kaydedildi: essay_1038_summary.txt\n",
      "Özet kaydedildi: essay_1039_summary.txt\n",
      "Özet kaydedildi: essay_104_summary.txt\n",
      "Özet kaydedildi: essay_1040_summary.txt\n",
      "Özet kaydedildi: essay_1041_summary.txt\n",
      "Özet kaydedildi: essay_1042_summary.txt\n",
      "Özet kaydedildi: essay_1043_summary.txt\n",
      "Özet kaydedildi: essay_1044_summary.txt\n",
      "Özet kaydedildi: essay_1045_summary.txt\n",
      "Özet kaydedildi: essay_1046_summary.txt\n",
      "Özet kaydedildi: essay_1047_summary.txt\n",
      "Özet kaydedildi: essay_1048_summary.txt\n",
      "Özet kaydedildi: essay_1049_summary.txt\n",
      "Özet kaydedildi: essay_105_summary.txt\n",
      "Özet kaydedildi: essay_1050_summary.txt\n",
      "Özet kaydedildi: essay_1051_summary.txt\n",
      "Özet kaydedildi: essay_1052_summary.txt\n",
      "Özet kaydedildi: essay_1053_summary.txt\n",
      "Özet kaydedildi: essay_1054_summary.txt\n",
      "Özet kaydedildi: essay_1055_summary.txt\n",
      "Özet kaydedildi: essay_1056_summary.txt\n",
      "Özet kaydedildi: essay_1057_summary.txt\n",
      "Özet kaydedildi: essay_1058_summary.txt\n",
      "Özet kaydedildi: essay_1059_summary.txt\n",
      "Özet kaydedildi: essay_106_summary.txt\n",
      "Özet kaydedildi: essay_1060_summary.txt\n",
      "Özet kaydedildi: essay_1061_summary.txt\n",
      "Özet kaydedildi: essay_1062_summary.txt\n",
      "Özet kaydedildi: essay_1063_summary.txt\n",
      "Özet kaydedildi: essay_1064_summary.txt\n",
      "Özet kaydedildi: essay_1065_summary.txt\n",
      "Özet kaydedildi: essay_1066_summary.txt\n",
      "Özet kaydedildi: essay_1067_summary.txt\n",
      "Özet kaydedildi: essay_1068_summary.txt\n",
      "Özet kaydedildi: essay_1069_summary.txt\n",
      "Özet kaydedildi: essay_107_summary.txt\n",
      "Özet kaydedildi: essay_1070_summary.txt\n",
      "Özet kaydedildi: essay_1071_summary.txt\n",
      "Özet kaydedildi: essay_1072_summary.txt\n",
      "Özet kaydedildi: essay_1073_summary.txt\n",
      "Özet kaydedildi: essay_1074_summary.txt\n",
      "Özet kaydedildi: essay_1075_summary.txt\n",
      "Özet kaydedildi: essay_1076_summary.txt\n",
      "Özet kaydedildi: essay_1077_summary.txt\n",
      "Özet kaydedildi: essay_1078_summary.txt\n",
      "Özet kaydedildi: essay_1079_summary.txt\n",
      "Özet kaydedildi: essay_108_summary.txt\n",
      "Özet kaydedildi: essay_1080_summary.txt\n",
      "Özet kaydedildi: essay_1081_summary.txt\n",
      "Özet kaydedildi: essay_1082_summary.txt\n",
      "Özet kaydedildi: essay_1083_summary.txt\n",
      "Özet kaydedildi: essay_1084_summary.txt\n",
      "Özet kaydedildi: essay_1085_summary.txt\n",
      "Özet kaydedildi: essay_1086_summary.txt\n",
      "Özet kaydedildi: essay_1087_summary.txt\n",
      "Özet kaydedildi: essay_1088_summary.txt\n",
      "Özet kaydedildi: essay_1089_summary.txt\n",
      "Özet kaydedildi: essay_109_summary.txt\n",
      "Özet kaydedildi: essay_1090_summary.txt\n",
      "Özet kaydedildi: essay_1091_summary.txt\n",
      "Özet kaydedildi: essay_1092_summary.txt\n",
      "Özet kaydedildi: essay_1093_summary.txt\n",
      "Özet kaydedildi: essay_1094_summary.txt\n",
      "Özet kaydedildi: essay_1095_summary.txt\n",
      "Özet kaydedildi: essay_1096_summary.txt\n",
      "Özet kaydedildi: essay_1097_summary.txt\n",
      "Özet kaydedildi: essay_1098_summary.txt\n",
      "Özet kaydedildi: essay_1099_summary.txt\n",
      "Özet kaydedildi: essay_11_summary.txt\n",
      "Özet kaydedildi: essay_110_summary.txt\n",
      "Özet kaydedildi: essay_1100_summary.txt\n",
      "Özet kaydedildi: essay_1101_summary.txt\n",
      "Özet kaydedildi: essay_1102_summary.txt\n",
      "Özet kaydedildi: essay_1103_summary.txt\n",
      "Özet kaydedildi: essay_1104_summary.txt\n",
      "Özet kaydedildi: essay_1105_summary.txt\n",
      "Özet kaydedildi: essay_1106_summary.txt\n",
      "Özet kaydedildi: essay_1107_summary.txt\n",
      "Özet kaydedildi: essay_1108_summary.txt\n",
      "Özet kaydedildi: essay_1109_summary.txt\n",
      "Özet kaydedildi: essay_111_summary.txt\n",
      "Özet kaydedildi: essay_1110_summary.txt\n",
      "Özet kaydedildi: essay_1111_summary.txt\n",
      "Özet kaydedildi: essay_1112_summary.txt\n",
      "Özet kaydedildi: essay_1113_summary.txt\n",
      "Özet kaydedildi: essay_1114_summary.txt\n",
      "Özet kaydedildi: essay_1115_summary.txt\n",
      "Özet kaydedildi: essay_1116_summary.txt\n",
      "Özet kaydedildi: essay_1117_summary.txt\n",
      "Özet kaydedildi: essay_1118_summary.txt\n",
      "Özet kaydedildi: essay_1119_summary.txt\n",
      "Özet kaydedildi: essay_112_summary.txt\n",
      "Özet kaydedildi: essay_1120_summary.txt\n",
      "Özet kaydedildi: essay_1121_summary.txt\n",
      "Özet kaydedildi: essay_1122_summary.txt\n",
      "Özet kaydedildi: essay_1123_summary.txt\n",
      "Özet kaydedildi: essay_1124_summary.txt\n",
      "Özet kaydedildi: essay_1125_summary.txt\n",
      "Özet kaydedildi: essay_1126_summary.txt\n",
      "Özet kaydedildi: essay_1127_summary.txt\n",
      "Özet kaydedildi: essay_1128_summary.txt\n",
      "Özet kaydedildi: essay_1129_summary.txt\n",
      "Özet kaydedildi: essay_113_summary.txt\n",
      "Özet kaydedildi: essay_1130_summary.txt\n",
      "Özet kaydedildi: essay_1131_summary.txt\n",
      "Özet kaydedildi: essay_1132_summary.txt\n",
      "Özet kaydedildi: essay_1133_summary.txt\n",
      "Özet kaydedildi: essay_1134_summary.txt\n",
      "Özet kaydedildi: essay_1135_summary.txt\n",
      "Özet kaydedildi: essay_1136_summary.txt\n",
      "Özet kaydedildi: essay_1137_summary.txt\n",
      "Özet kaydedildi: essay_1138_summary.txt\n",
      "Özet kaydedildi: essay_1139_summary.txt\n",
      "Özet kaydedildi: essay_114_summary.txt\n",
      "Özet kaydedildi: essay_1140_summary.txt\n",
      "Özet kaydedildi: essay_1141_summary.txt\n",
      "Özet kaydedildi: essay_1142_summary.txt\n",
      "Özet kaydedildi: essay_1143_summary.txt\n",
      "Özet kaydedildi: essay_1144_summary.txt\n",
      "Özet kaydedildi: essay_1145_summary.txt\n",
      "Özet kaydedildi: essay_1146_summary.txt\n",
      "Özet kaydedildi: essay_1147_summary.txt\n",
      "Özet kaydedildi: essay_1148_summary.txt\n",
      "Özet kaydedildi: essay_1149_summary.txt\n",
      "Özet kaydedildi: essay_115_summary.txt\n",
      "Özet kaydedildi: essay_1150_summary.txt\n",
      "Özet kaydedildi: essay_1151_summary.txt\n",
      "Özet kaydedildi: essay_1152_summary.txt\n",
      "Özet kaydedildi: essay_1153_summary.txt\n",
      "Özet kaydedildi: essay_1154_summary.txt\n",
      "Özet kaydedildi: essay_1155_summary.txt\n",
      "Özet kaydedildi: essay_1156_summary.txt\n",
      "Özet kaydedildi: essay_1157_summary.txt\n",
      "Özet kaydedildi: essay_1158_summary.txt\n",
      "Özet kaydedildi: essay_1159_summary.txt\n",
      "Özet kaydedildi: essay_116_summary.txt\n",
      "Özet kaydedildi: essay_1160_summary.txt\n",
      "Özet kaydedildi: essay_1161_summary.txt\n",
      "Özet kaydedildi: essay_1162_summary.txt\n",
      "Özet kaydedildi: essay_1163_summary.txt\n",
      "Özet kaydedildi: essay_1164_summary.txt\n",
      "Özet kaydedildi: essay_1165_summary.txt\n",
      "Özet kaydedildi: essay_1166_summary.txt\n",
      "Özet kaydedildi: essay_1167_summary.txt\n",
      "Özet kaydedildi: essay_1168_summary.txt\n",
      "Özet kaydedildi: essay_1169_summary.txt\n",
      "Özet kaydedildi: essay_117_summary.txt\n",
      "Özet kaydedildi: essay_1170_summary.txt\n",
      "Özet kaydedildi: essay_1171_summary.txt\n",
      "Özet kaydedildi: essay_1172_summary.txt\n",
      "Özet kaydedildi: essay_1173_summary.txt\n",
      "Özet kaydedildi: essay_1174_summary.txt\n",
      "Özet kaydedildi: essay_1175_summary.txt\n",
      "Özet kaydedildi: essay_1176_summary.txt\n",
      "Özet kaydedildi: essay_1177_summary.txt\n",
      "Özet kaydedildi: essay_1178_summary.txt\n",
      "Özet kaydedildi: essay_1179_summary.txt\n",
      "Özet kaydedildi: essay_118_summary.txt\n",
      "Özet kaydedildi: essay_1180_summary.txt\n",
      "Özet kaydedildi: essay_1181_summary.txt\n",
      "Özet kaydedildi: essay_1182_summary.txt\n",
      "Özet kaydedildi: essay_1183_summary.txt\n",
      "Özet kaydedildi: essay_1184_summary.txt\n",
      "Özet kaydedildi: essay_1185_summary.txt\n",
      "Özet kaydedildi: essay_1186_summary.txt\n",
      "Özet kaydedildi: essay_1187_summary.txt\n",
      "Özet kaydedildi: essay_1188_summary.txt\n",
      "Özet kaydedildi: essay_1189_summary.txt\n",
      "Özet kaydedildi: essay_119_summary.txt\n",
      "Özet kaydedildi: essay_1190_summary.txt\n",
      "Özet kaydedildi: essay_1191_summary.txt\n",
      "Özet kaydedildi: essay_1192_summary.txt\n",
      "Özet kaydedildi: essay_1193_summary.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Özet üret\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m summary_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(inputs, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, min_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, length_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Özet dosyasını kaydet\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2484\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[0;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2482\u001b[0m     )\n\u001b[0;32m   2483\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2484\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2485\u001b[0m         input_ids,\n\u001b[0;32m   2486\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2487\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2488\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2489\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2490\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2491\u001b[0m     )\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2494\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2495\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2496\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2497\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2503\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2504\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3904\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3901\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3902\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m-> 3904\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3906\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3907\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3908\u001b[0m     model_outputs,\n\u001b[0;32m   3909\u001b[0m     model_kwargs,\n\u001b[0;32m   3910\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3911\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1654\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1650\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1651\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1652\u001b[0m         )\n\u001b[1;32m-> 1654\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1655\u001b[0m     input_ids,\n\u001b[0;32m   1656\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1657\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1658\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[0;32m   1659\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1660\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1661\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1662\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1663\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1664\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1665\u001b[0m     decoder_inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1666\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1667\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1668\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1669\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1672\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1673\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1533\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1526\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1527\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1528\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1529\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1530\u001b[0m     )\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1533\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[0;32m   1534\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1535\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1536\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1537\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1538\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1539\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1540\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1541\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1542\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1543\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1544\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1545\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1546\u001b[0m )\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1378\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1366\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1367\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         use_cache,\n\u001b[0;32m   1376\u001b[0m     )\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m   1379\u001b[0m         hidden_states,\n\u001b[0;32m   1380\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1381\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1382\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1383\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39m(head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1384\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1385\u001b[0m             cross_attn_head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m         ),\n\u001b[0;32m   1387\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[0;32m   1388\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1389\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1390\u001b[0m     )\n\u001b[0;32m   1391\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:683\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m    682\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_attn(\n\u001b[0;32m    684\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    685\u001b[0m     key_value_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    686\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    687\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_layer_head_mask,\n\u001b[0;32m    688\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mcross_attn_past_key_value,\n\u001b[0;32m    689\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    691\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:448\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    445\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# get query proj\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# get key, value proj\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# `past_key_value[0].shape[2] == key_value_states.shape[1]`\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# is checking that the `sequence_length` of the `past_key_value` is the same as\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# the provided `key_value_states` to support prefix tuning\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     is_cross_attention\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m past_key_value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m key_value_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    457\u001b[0m ):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# reuse k,v, cross_attentions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Anahtar kelimesiz sadece özet çıkarıyor\n",
    "\n",
    "import os\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# GPU varsa kullan, yoksa CPU\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Kullanılan aygıt:\", \"GPU\" if device == 0 else \"CPU\")\n",
    "\n",
    "# Model ve tokenizer'ı yükle\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Girdi ve çıktı klasör yolları\n",
    "input_folder = \"/HuggingFace_Dataset\"\n",
    "output_folder = \"/Ozetler_hug\"\n",
    "\n",
    "# Çıktı klasörü yoksa oluştur\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Her .txt dosyası için işle\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Dosya oku\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize et\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        # Özet üret\n",
    "        summary_ids = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Özet dosyasını kaydet\n",
    "        summary_filename = filename.replace(\".txt\", \"_summary.txt\")\n",
    "        output_path = os.path.join(output_folder, summary_filename)\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as summary_file:\n",
    "            summary_file.write(summary)\n",
    "\n",
    "        print(f\"Özet kaydedildi: {summary_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97b8612-a53c-4153-884d-bcb82b5e9921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.40.1\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.1)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers==4.40.1) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.40.1) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.1) (2025.1.31)\n",
      "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 0.0/9.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.2/9.0 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.3/9.0 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.0/9.0 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "Successfully installed tokenizers-0.19.1 transformers-4.40.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.40.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25bc06d-ee27-4d4b-9c47-42f4240f49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d321e173836647e68b9a5d88edfcf790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.40.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a03bf61-e584-408b-bc89-ccea71e8e9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_100_summary.txt -> ['social issues', 'culture', 'law']\n",
      "essay_101_summary.txt -> ['culture', 'social issues', 'environment']\n",
      "essay_102_summary.txt -> ['business', 'design', 'management']\n",
      "essay_103_summary.txt -> ['health', 'media', 'management']\n",
      "essay_104_summary.txt -> ['business', 'management', 'culture']\n",
      "essay_105_summary.txt -> ['design', 'business', 'law']\n",
      "essay_106_summary.txt -> ['media', 'psychology', 'health']\n",
      "essay_107_summary.txt -> ['law', 'social issues', 'education']\n",
      "essay_108_summary.txt -> ['culture', 'design', 'business']\n",
      "essay_109_summary.txt -> ['management', 'culture', 'environment']\n",
      "essay_10_summary.txt -> ['media', 'law', 'culture']\n",
      "essay_110_summary.txt -> ['health', 'management', 'media']\n",
      "essay_111_summary.txt -> ['health', 'media', 'management']\n",
      "essay_112_summary.txt -> ['art', 'media', 'design']\n",
      "essay_113_summary.txt -> ['environment', 'management', 'culture']\n",
      "essay_114_summary.txt -> ['health', 'environment', 'design']\n",
      "essay_115_summary.txt -> ['education', 'psychology', 'culture']\n",
      "essay_116_summary.txt -> ['religion', 'culture', 'design']\n",
      "essay_117_summary.txt -> ['social issues', 'law', 'media']\n",
      "essay_118_summary.txt -> ['social issues', 'health', 'environment']\n",
      "essay_119_summary.txt -> ['health', 'environment', 'law']\n",
      "essay_11_summary.txt -> ['transportation', 'design', 'management']\n",
      "essay_120_summary.txt -> ['business', 'management', 'transportation']\n",
      "essay_121_summary.txt -> ['media', 'culture', 'history']\n",
      "essay_122_summary.txt -> ['media', 'psychology', 'social issues']\n",
      "essay_123_summary.txt -> ['health', 'formal sciences', 'transportation']\n",
      "essay_124_summary.txt -> ['history', 'culture', 'media']\n",
      "essay_125_summary.txt -> ['culture', 'environment', 'media']\n",
      "essay_126_summary.txt -> ['business', 'management', 'culture']\n",
      "essay_127_summary.txt -> ['social issues', 'media', 'formal sciences']\n",
      "essay_128_summary.txt -> ['social issues', 'media', 'culture']\n",
      "essay_129_summary.txt -> ['religion', 'transportation', 'history']\n",
      "essay_12_summary.txt -> ['health', 'social issues', 'media']\n",
      "essay_130_summary.txt -> ['social issues', 'psychology', 'culture']\n",
      "essay_131_summary.txt -> ['media', 'law', 'social issues']\n",
      "essay_132_summary.txt -> ['health', 'history', 'social issues']\n",
      "essay_133_summary.txt -> ['environment', 'health', 'culture']\n",
      "essay_134_summary.txt -> ['transportation', 'environment', 'media']\n",
      "essay_135_summary.txt -> ['health', 'design', 'management']\n",
      "essay_136_summary.txt -> ['music', 'culture', 'history']\n",
      "essay_137_summary.txt -> ['history', 'formal sciences', 'health']\n",
      "essay_138_summary.txt -> ['management', 'business', 'health']\n",
      "essay_139_summary.txt -> ['business', 'management', 'culture']\n",
      "essay_13_summary.txt -> ['media', 'social issues', 'culture']\n",
      "essay_140_summary.txt -> ['social issues', 'culture', 'environment']\n",
      "essay_141_summary.txt -> ['history', 'formal sciences', 'law']\n",
      "essay_142_summary.txt -> ['health', 'culture', 'environment']\n",
      "essay_143_summary.txt -> ['media', 'environment', 'history']\n",
      "essay_144_summary.txt -> ['social issues', 'law', 'business']\n",
      "essay_145_summary.txt -> ['business', 'management', 'environment']\n",
      "essay_146_summary.txt -> ['business', 'health', 'management']\n",
      "essay_147_summary.txt -> ['economics', 'business', 'management']\n",
      "essay_148_summary.txt -> ['psychology', 'media', 'design']\n",
      "essay_149_summary.txt -> ['health', 'management', 'media']\n",
      "essay_14_summary.txt -> ['art', 'media', 'environment']\n",
      "essay_150_summary.txt -> ['social issues', 'culture', 'design']\n",
      "essay_151_summary.txt -> ['health', 'media', 'culture']\n",
      "essay_152_summary.txt -> ['business', 'environment', 'management']\n",
      "essay_153_summary.txt -> ['social issues', 'economics', 'history']\n",
      "essay_154_summary.txt -> ['health', 'management', 'formal sciences']\n",
      "essay_155_summary.txt -> ['health', 'management', 'design']\n",
      "essay_156_summary.txt -> ['music', 'culture', 'media']\n",
      "essay_157_summary.txt -> ['media', 'culture', 'history']\n",
      "essay_158_summary.txt -> ['psychology', 'management', 'health']\n",
      "essay_159_summary.txt -> ['health', 'media', 'management']\n",
      "essay_15_summary.txt -> ['social issues', 'media', 'culture']\n",
      "essay_160_summary.txt -> ['environment', 'design', 'health']\n",
      "essay_161_summary.txt -> ['history', 'media', 'culture']\n",
      "essay_162_summary.txt -> ['social issues', 'culture', 'history']\n",
      "essay_163_summary.txt -> ['media', 'music', 'art']\n",
      "essay_164_summary.txt -> ['business', 'management', 'culture']\n",
      "essay_165_summary.txt -> ['transportation', 'art', 'culture']\n",
      "essay_166_summary.txt -> ['culture', 'media', 'religion']\n",
      "essay_167_summary.txt -> ['business', 'management', 'design']\n",
      "essay_168_summary.txt -> ['formal sciences', 'business', 'law']\n",
      "essay_169_summary.txt -> ['art', 'media', 'culture']\n",
      "essay_16_summary.txt -> ['law', 'culture', 'design']\n",
      "essay_170_summary.txt -> ['economics', 'art', 'business']\n",
      "essay_171_summary.txt -> ['formal sciences', 'health', 'media']\n",
      "essay_172_summary.txt -> ['health', 'media', 'management']\n",
      "essay_173_summary.txt -> ['environment', 'media', 'law']\n",
      "essay_174_summary.txt -> ['culture', 'design', 'education']\n",
      "essay_175_summary.txt -> ['religion', 'education', 'media']\n",
      "essay_176_summary.txt -> ['religion', 'culture', 'history']\n",
      "essay_177_summary.txt -> ['health', 'media', 'management']\n",
      "essay_178_summary.txt -> ['social issues', 'culture', 'media']\n",
      "essay_179_summary.txt -> ['environment', 'law', 'history']\n",
      "essay_17_summary.txt -> ['health', 'management', 'formal sciences']\n",
      "essay_180_summary.txt -> ['environment', 'business', 'management']\n",
      "essay_181_summary.txt -> ['business', 'management', 'formal sciences']\n",
      "essay_182_summary.txt -> ['health', 'media', 'environment']\n",
      "essay_183_summary.txt -> ['history', 'media', 'law']\n",
      "essay_184_summary.txt -> ['health', 'design', 'environment']\n",
      "essay_185_summary.txt -> ['environment', 'management', 'health']\n",
      "essay_186_summary.txt -> ['environment', 'health', 'social issues']\n",
      "essay_187_summary.txt -> ['social issues', 'health', 'environment']\n",
      "essay_188_summary.txt -> ['health', 'social issues', 'environment']\n",
      "essay_189_summary.txt -> ['health', 'formal sciences', 'environment']\n",
      "essay_18_summary.txt -> ['social issues', 'law', 'culture']\n",
      "essay_190_summary.txt -> ['management', 'law', 'environment']\n",
      "essay_191_summary.txt -> ['culture', 'management', 'social issues']\n",
      "essay_192_summary.txt -> ['economics', 'law', 'business']\n",
      "essay_193_summary.txt -> ['social issues', 'law', 'culture']\n",
      "essay_194_summary.txt -> ['health', 'management', 'environment']\n",
      "essay_195_summary.txt -> ['culture', 'design', 'social issues']\n",
      "essay_196_summary.txt -> ['social issues', 'law', 'culture']\n",
      "essay_197_summary.txt -> ['media', 'environment', 'social issues']\n",
      "essay_198_summary.txt -> ['music', 'media', 'culture']\n",
      "essay_199_summary.txt -> ['health', 'design', 'business']\n",
      "essay_19_summary.txt -> ['design', 'business', 'environment']\n",
      "essay_1_summary.txt -> ['media', 'social issues', 'history']\n",
      "essay_200_summary.txt -> ['management', 'law', 'health']\n",
      "essay_201_summary.txt -> ['business', 'transportation', 'health']\n",
      "essay_202_summary.txt -> ['social issues', 'education', 'health']\n",
      "essay_203_summary.txt -> ['law', 'psychology', 'management']\n",
      "essay_204_summary.txt -> ['health', 'formal sciences', 'design']\n",
      "essay_205_summary.txt -> ['health', 'social issues', 'media']\n",
      "essay_206_summary.txt -> ['health', 'formal sciences', 'design']\n",
      "essay_207_summary.txt -> ['health', 'design', 'culture']\n",
      "essay_208_summary.txt -> ['law', 'health', 'culture']\n",
      "essay_209_summary.txt -> ['law', 'design', 'social issues']\n",
      "essay_20_summary.txt -> ['culture', 'media', 'environment']\n",
      "essay_210_summary.txt -> ['social issues', 'psychology', 'formal sciences']\n",
      "essay_211_summary.txt -> ['history', 'culture', 'social issues']\n",
      "essay_212_summary.txt -> ['social issues', 'media', 'history']\n",
      "essay_213_summary.txt -> ['management', 'environment', 'design']\n",
      "essay_214_summary.txt -> ['culture', 'health', 'social issues']\n",
      "essay_215_summary.txt -> ['culture', 'business', 'management']\n",
      "essay_216_summary.txt -> ['social issues', 'art', 'culture']\n",
      "essay_217_summary.txt -> ['culture', 'social issues', 'management']\n",
      "essay_218_summary.txt -> ['culture', 'social issues', 'management']\n",
      "essay_219_summary.txt -> ['culture', 'social issues', 'management']\n",
      "essay_21_summary.txt -> ['design', 'media', 'management']\n",
      "essay_220_summary.txt -> ['social issues', 'health', 'media']\n",
      "essay_221_summary.txt -> ['education', 'formal sciences', 'history']\n",
      "essay_222_summary.txt -> ['transportation', 'business', 'media']\n",
      "essay_223_summary.txt -> ['business', 'media', 'law']\n",
      "essay_224_summary.txt -> ['art', 'media', 'psychology']\n",
      "essay_225_summary.txt -> ['design', 'management', 'environment']\n",
      "essay_226_summary.txt -> ['health', 'education', 'environment']\n",
      "essay_227_summary.txt -> ['environment', 'media', 'business']\n",
      "essay_228_summary.txt -> ['culture', 'social issues', 'health']\n",
      "essay_229_summary.txt -> ['business', 'management', 'health']\n",
      "essay_22_summary.txt -> ['health', 'business', 'design']\n",
      "essay_230_summary.txt -> ['health', 'media', 'law']\n",
      "essay_231_summary.txt -> ['health', 'media', 'management']\n",
      "essay_232_summary.txt -> ['culture', 'history', 'social issues']\n",
      "essay_233_summary.txt -> ['culture', 'media', 'environment']\n",
      "essay_234_summary.txt -> ['psychology', 'culture', 'media']\n",
      "essay_235_summary.txt -> ['media', 'psychology', 'culture']\n",
      "essay_236_summary.txt -> ['health', 'design', 'management']\n",
      "essay_237_summary.txt -> ['psychology', 'health', 'formal sciences']\n",
      "essay_238_summary.txt -> ['business', 'economics', 'environment']\n",
      "essay_239_summary.txt -> ['health', 'management', 'media']\n",
      "essay_23_summary.txt -> ['art', 'media', 'history']\n",
      "essay_240_summary.txt -> ['health', 'management', 'culture']\n",
      "essay_241_summary.txt -> ['health', 'management', 'media']\n",
      "essay_242_summary.txt -> ['health', 'formal sciences', 'law']\n",
      "essay_243_summary.txt -> ['business', 'economics', 'social issues']\n",
      "essay_244_summary.txt -> ['health', 'design', 'media']\n",
      "essay_245_summary.txt -> ['business', 'environment', 'management']\n",
      "essay_246_summary.txt -> ['religion', 'management', 'social issues']\n",
      "essay_247_summary.txt -> ['law', 'social issues', 'design']\n",
      "essay_248_summary.txt -> ['religion', 'law', 'business']\n",
      "essay_249_summary.txt -> ['transportation', 'religion', 'management']\n",
      "essay_24_summary.txt -> ['education', 'media', 'environment']\n",
      "essay_250_summary.txt -> ['social issues', 'media', 'culture']\n",
      "essay_251_summary.txt -> ['religion', 'social issues', 'culture']\n",
      "essay_252_summary.txt -> ['health', 'media', 'business']\n",
      "essay_253_summary.txt -> ['art', 'media', 'culture']\n",
      "essay_254_summary.txt -> ['psychology', 'design', 'media']\n",
      "essay_255_summary.txt -> ['culture', 'environment', 'management']\n",
      "essay_256_summary.txt -> ['business', 'management', 'media']\n",
      "essay_257_summary.txt -> ['culture', 'social issues', 'environment']\n",
      "essay_258_summary.txt -> ['law', 'social issues', 'culture']\n",
      "essay_259_summary.txt -> ['history', 'social issues', 'business']\n",
      "essay_25_summary.txt -> ['education', 'business', 'management']\n",
      "essay_260_summary.txt -> ['law', 'design', 'social issues']\n",
      "essay_261_summary.txt -> ['business', 'management', 'health']\n",
      "essay_262_summary.txt -> ['business', 'social issues', 'media']\n",
      "essay_263_summary.txt -> ['law', 'media', 'environment']\n",
      "essay_264_summary.txt -> ['health', 'social issues', 'design']\n",
      "essay_265_summary.txt -> ['environment', 'social issues', 'media']\n",
      "essay_266_summary.txt -> ['management', 'business', 'economics']\n",
      "essay_267_summary.txt -> ['social issues', 'health', 'media']\n",
      "essay_268_summary.txt -> ['health', 'law', 'social issues']\n",
      "essay_269_summary.txt -> ['health', 'formal sciences', 'law']\n",
      "essay_26_summary.txt -> ['business', 'economics', 'design']\n",
      "essay_270_summary.txt -> ['culture', 'media', 'business']\n",
      "essay_271_summary.txt -> ['media', 'culture', 'business']\n",
      "essay_272_summary.txt -> ['culture', 'music', 'business']\n",
      "essay_273_summary.txt -> ['health', 'business', 'economics']\n",
      "essay_274_summary.txt -> ['health', 'management', 'business']\n",
      "essay_275_summary.txt -> ['social issues', 'culture', 'environment']\n",
      "essay_276_summary.txt -> ['social issues', 'culture', 'law']\n",
      "essay_277_summary.txt -> ['business', 'management', 'economics']\n",
      "essay_278_summary.txt -> ['law', 'media', 'culture']\n",
      "essay_279_summary.txt -> ['social issues', 'culture', 'media']\n",
      "essay_27_summary.txt -> ['art', 'media', 'culture']\n",
      "essay_280_summary.txt -> ['health', 'social issues', 'formal sciences']\n",
      "essay_281_summary.txt -> ['media', 'law', 'psychology']\n",
      "essay_282_summary.txt -> ['environment', 'health', 'design']\n",
      "essay_283_summary.txt -> ['environment', 'culture', 'design']\n",
      "essay_284_summary.txt -> ['health', 'media', 'environment']\n",
      "essay_285_summary.txt -> ['economics', 'social issues', 'psychology']\n",
      "essay_286_summary.txt -> ['media', 'environment', 'culture']\n",
      "essay_287_summary.txt -> ['social issues', 'education', 'environment']\n",
      "essay_288_summary.txt -> ['health', 'media', 'formal sciences']\n",
      "essay_289_summary.txt -> ['transportation', 'environment', 'health']\n",
      "essay_28_summary.txt -> ['media', 'social issues', 'culture']\n",
      "essay_290_summary.txt -> ['formal sciences', 'history', 'psychology']\n",
      "essay_291_summary.txt -> ['management', 'environment', 'law']\n",
      "essay_292_summary.txt -> ['business', 'design', 'art']\n",
      "essay_293_summary.txt -> ['transportation', 'health', 'environment']\n",
      "essay_294_summary.txt -> ['health', 'management', 'media']\n",
      "essay_295_summary.txt -> ['social issues', 'art', 'music']\n",
      "essay_296_summary.txt -> ['health', 'history', 'law']\n",
      "essay_297_summary.txt -> ['law', 'business', 'media']\n",
      "essay_298_summary.txt -> ['health', 'management', 'social issues']\n",
      "essay_299_summary.txt -> ['social issues', 'media', 'law']\n",
      "essay_29_summary.txt -> ['social issues', 'culture', 'media']\n",
      "essay_2_summary.txt -> ['media', 'management', 'business']\n",
      "essay_300_summary.txt -> ['social issues', 'media', 'health']\n",
      "essay_30_summary.txt -> ['business', 'environment', 'media']\n",
      "essay_31_summary.txt -> ['music', 'media', 'culture']\n",
      "essay_32_summary.txt -> ['business', 'management', 'education']\n",
      "essay_33_summary.txt -> ['environment', 'design', 'business']\n",
      "essay_34_summary.txt -> ['law', 'social issues', 'history']\n",
      "essay_35_summary.txt -> ['health', 'media', 'management']\n",
      "essay_36_summary.txt -> ['economics', 'social issues', 'health']\n",
      "essay_37_summary.txt -> ['health', 'social issues', 'media']\n",
      "essay_38_summary.txt -> ['social issues', 'environment', 'culture']\n",
      "essay_39_summary.txt -> ['social issues', 'health', 'culture']\n",
      "essay_3_summary.txt -> ['media', 'psychology', 'business']\n",
      "essay_40_summary.txt -> ['business', 'health', 'history']\n",
      "essay_41_summary.txt -> ['religion', 'culture', 'design']\n",
      "essay_42_summary.txt -> ['transportation', 'business', 'management']\n",
      "essay_43_summary.txt -> ['education', 'social issues', 'environment']\n",
      "essay_44_summary.txt -> ['social issues', 'religion', 'art']\n",
      "essay_45_summary.txt -> ['health', 'media', 'management']\n",
      "essay_46_summary.txt -> ['social issues', 'management', 'culture']\n",
      "essay_47_summary.txt -> ['environment', 'business', 'culture']\n",
      "essay_48_summary.txt -> ['culture', 'art', 'history']\n",
      "essay_49_summary.txt -> ['culture', 'psychology', 'environment']\n",
      "essay_4_summary.txt -> ['environment', 'social issues', 'law']\n",
      "essay_50_summary.txt -> ['management', 'design', 'law']\n",
      "essay_51_summary.txt -> ['law', 'social issues', 'history']\n",
      "essay_52_summary.txt -> ['social issues', 'culture', 'management']\n",
      "essay_53_summary.txt -> ['health', 'social issues', 'psychology']\n",
      "essay_54_summary.txt -> ['media', 'art', 'management']\n",
      "essay_55_summary.txt -> ['health', 'media', 'law']\n",
      "essay_56_summary.txt -> ['business', 'management', 'environment']\n",
      "essay_57_summary.txt -> ['media', 'business', 'economics']\n",
      "essay_58_summary.txt -> ['business', 'social issues', 'management']\n",
      "essay_59_summary.txt -> ['art', 'music', 'media']\n",
      "essay_5_summary.txt -> ['business', 'management', 'economics']\n",
      "essay_60_summary.txt -> ['social issues', 'media', 'culture']\n",
      "essay_61_summary.txt -> ['health', 'media', 'formal sciences']\n",
      "essay_62_summary.txt -> ['social issues', 'culture', 'design']\n",
      "essay_63_summary.txt -> ['social issues', 'business', 'management']\n",
      "essay_64_summary.txt -> ['religion', 'media', 'psychology']\n",
      "essay_65_summary.txt -> ['culture', 'social issues', 'environment']\n",
      "essay_66_summary.txt -> ['business', 'management', 'culture']\n",
      "essay_67_summary.txt -> ['social issues', 'law', 'business']\n",
      "essay_68_summary.txt -> ['environment', 'economics', 'management']\n",
      "essay_69_summary.txt -> ['business', 'formal sciences', 'management']\n",
      "essay_6_summary.txt -> ['health', 'culture', 'environment']\n",
      "essay_70_summary.txt -> ['music', 'social issues', 'art']\n",
      "essay_71_summary.txt -> ['culture', 'social issues', 'media']\n",
      "essay_72_summary.txt -> ['health', 'management', 'environment']\n",
      "essay_73_summary.txt -> ['art', 'media', 'social issues']\n",
      "essay_74_summary.txt -> ['design', 'management', 'media']\n",
      "essay_75_summary.txt -> ['health', 'management', 'education']\n",
      "essay_76_summary.txt -> ['art', 'culture', 'media']\n",
      "essay_77_summary.txt -> ['art', 'media', 'culture']\n",
      "essay_78_summary.txt -> ['music', 'culture', 'law']\n",
      "essay_79_summary.txt -> ['music', 'health', 'media']\n",
      "essay_7_summary.txt -> ['media', 'environment', 'design']\n",
      "essay_80_summary.txt -> ['social issues', 'economics', 'design']\n",
      "essay_81_summary.txt -> ['education', 'formal sciences', 'media']\n",
      "essay_82_summary.txt -> ['environment', 'media', 'design']\n",
      "essay_83_summary.txt -> ['media', 'culture', 'social issues']\n",
      "essay_84_summary.txt -> ['environment', 'law', 'psychology']\n",
      "essay_85_summary.txt -> ['culture', 'health', 'media']\n",
      "essay_86_summary.txt -> ['business', 'management', 'environment']\n",
      "essay_87_summary.txt -> ['media', 'design', 'art']\n",
      "essay_88_summary.txt -> ['management', 'environment', 'business']\n",
      "essay_89_summary.txt -> ['environment', 'health', 'law']\n",
      "essay_8_summary.txt -> ['culture', 'social issues', 'environment']\n",
      "essay_90_summary.txt -> ['business', 'social issues', 'health']\n",
      "essay_91_summary.txt -> ['environment', 'media', 'design']\n",
      "essay_92_summary.txt -> ['health', 'management', 'media']\n",
      "essay_93_summary.txt -> ['art', 'law', 'culture']\n",
      "essay_94_summary.txt -> ['media', 'culture', 'environment']\n",
      "essay_95_summary.txt -> ['formal sciences', 'management', 'environment']\n",
      "essay_96_summary.txt -> ['business', 'management', 'environment']\n",
      "essay_97_summary.txt -> ['business', 'environment', 'health']\n",
      "essay_98_summary.txt -> ['business', 'management', 'environment']\n",
      "essay_99_summary.txt -> ['social issues', 'law', 'culture']\n",
      "essay_9_summary.txt -> ['psychology', 'media', 'culture']\n",
      "\n",
      "Tüm veriler kaydedildi: C:/Users/Lenovo/Desktop/etiketli_ozetler.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "# Zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Etiketler\n",
    "labels = [\n",
    "    \"art\", \"business\", \"culture\", \"design\", \"economics\",\n",
    "    \"education\", \"media\", \"environment\", \"formal sciences\", \"health\", \"history\", \"law\",\n",
    "    \"management\", \"music\", \"psychology\", \"religion\",\n",
    "    \"social issues\", \"transportation\"\n",
    "]\n",
    "\n",
    "# Girdi klasörü (daha önce özet ve anahtar kelime yazdığın yer)\n",
    "summary_folder = \"/Ozetler_hug\"\n",
    "output_file = \"/etiketli_ozetler.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for filename in os.listdir(summary_folder):\n",
    "    if filename.endswith(\"_summary.txt\"):\n",
    "        path = os.path.join(summary_folder, filename)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Sadece özeti al (ilk bölüm)\n",
    "        summary_part = content.split(\"----- ANAHTAR KELİMELER -----\")[0].replace(\"----- ÖZET -----\", \"\").strip()\n",
    "\n",
    "        # Zero-shot classification ile label tahmini\n",
    "        result = classifier(summary_part, candidate_labels=labels, multi_label=True)\n",
    "        top_labels = result[\"labels\"][:3]  # En güçlü 3 label'ı al\n",
    "\n",
    "        rows.append({\n",
    "            \"filename\": filename,\n",
    "            \"summary\": summary_part,\n",
    "            \"predicted_labels\": \", \".join(top_labels)\n",
    "        })\n",
    "\n",
    "        print(f\"{filename} -> {top_labels}\")\n",
    "\n",
    "# CSV olarak dışa aktar\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nTüm veriler kaydedildi: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69ab6e9-129e-4d47-ae63-448ae1a336c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:24:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:24:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:24:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam tahmin edilen pozitif etiket sayısı: 143\n",
      "📊 Classification Report:\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "            art       0.00      0.00      0.00         6\n",
      "       business       0.80      0.20      0.32        20\n",
      "        culture       0.38      0.31      0.34        26\n",
      "         design       0.25      0.07      0.11        14\n",
      "      economics       0.00      0.00      0.00         4\n",
      "      education       0.00      0.00      0.00         5\n",
      "    environment       0.29      0.07      0.11        28\n",
      "formal sciences       0.00      0.00      0.00         7\n",
      "         health       0.53      0.26      0.35        38\n",
      "        history       0.00      0.00      0.00         5\n",
      "            law       0.40      0.22      0.29        18\n",
      "     management       0.33      0.12      0.18        24\n",
      "          media       0.33      0.34      0.34        29\n",
      "          music       0.00      0.00      0.00         1\n",
      "     psychology       0.00      0.00      0.00         8\n",
      "       religion       0.00      0.00      0.00         6\n",
      "  social issues       0.50      0.54      0.52        28\n",
      " transportation       0.00      0.00      0.00         3\n",
      "\n",
      "      micro avg       0.40      0.21      0.28       270\n",
      "      macro avg       0.21      0.12      0.14       270\n",
      "   weighted avg       0.36      0.21      0.25       270\n",
      "    samples avg       0.36      0.21      0.26       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Veriyi oku\n",
    "df = pd.read_csv(\"/etiketli_ozetler.csv\")\n",
    "\n",
    "# Etiketleri listeye çevir (örn: \"art, culture\" -> [\"art\", \"culture\"])\n",
    "df[\"labels_list\"] = df[\"predicted_labels\"].apply(lambda x: [label.strip() for label in x.split(\",\")])\n",
    "\n",
    "# Özeti ve etiketleri al\n",
    "texts = df[\"summary\"].tolist()\n",
    "labels = df[\"labels_list\"].tolist()\n",
    "\n",
    "# TF-IDF vektörleştirme\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Multi-label etiketleri binarize et\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(labels)\n",
    "\n",
    "# Eğitim/test ayrımı\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Tahmin\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Toplam tahmin edilen pozitif etiket sayısı:\", Y_pred.sum())\n",
    "\n",
    "\n",
    "# Rapor\n",
    "print(\" Classification Report:\\n\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2674ff8-1bba-4607-8aea-a7e3442836b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 04:18, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.410705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.372353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.356550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.350650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=0.3705934445063273, metrics={'train_runtime': 260.3818, 'train_samples_per_second': 3.687, 'train_steps_per_second': 0.922, 'total_flos': 54274450982400.0, 'train_loss': 0.3705934445063273, 'epoch': 4.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertPreTrainedModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#  Veri yükleme ve ön işleme\n",
    "    df = pd.read_csv(\"/etiketli_ozetler.csv\")\n",
    "df[\"labels_list\"] = df[\"predicted_labels\"].apply(lambda x: [l.strip() for l in x.split(\",\")])\n",
    "texts = df[\"summary\"].tolist()\n",
    "labels = df[\"labels_list\"].tolist()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(labels)\n",
    "num_labels = len(mlb.classes_)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(texts, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Tokenizer ve dataset tanımı\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(X_train, Y_train, tokenizer)\n",
    "val_dataset = TextDataset(X_val, Y_val, tokenizer)\n",
    "\n",
    "#  Model tanımı\n",
    "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.pooler_output)\n",
    "        probs = self.sigmoid(logits)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.BCELoss()\n",
    "            loss = loss_fn(probs, labels)\n",
    "        return {\"loss\": loss, \"logits\": probs}\n",
    "\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "#  Eğitim ayarları\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=4,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46cec121-7e35-4fad-889d-77dc7db92267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3490833342075348, 'eval_accuracy': 0.016666666666666666, 'eval_precision': 0.6027777777777777, 'eval_recall': 0.2999999999999999, 'eval_f1': 0.3877777777777778, 'eval_runtime': 2.299, 'eval_samples_per_second': 26.099, 'eval_steps_per_second': 6.525}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import Trainer\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    y_true = pred.label_ids\n",
    "    y_pred = (pred.predictions > 0.5).astype(int)  # Çoklu etiket için eşik 0.5\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"samples\", zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"samples\", zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"samples\", zero_division=0),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb5ecca-f1e7-416b-a8d0-58f3556d6b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Özetleme pipeline'ı\n",
    "ozetleyici = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Multi-label sınıflandırma için text classification pipeline\n",
    "etiketleyici = pipeline(\"zero-shot-classification\",\n",
    "                        model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Etiket sınıflarını tanımla (kendi etiketlerine göre güncelle)\n",
    "etiket_siniflari = [\n",
    "    \"art\", \"business\", \"culture\", \"design\", \"economics\",\n",
    "    \"education\", \"media\", \"environment\", \"formal sciences\", \"health\", \"history\", \"law\",\n",
    "    \"management\", \"music\", \"psychology\", \"religion\",\n",
    "    \"social issues\", \"transportation\"\n",
    "]\n",
    "\n",
    "def ozetle(text):\n",
    "    # Özet uzunluğu ayarlanabilir\n",
    "    max_len = 130\n",
    "    summary = ozetleyici(text, max_length=max_len, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "def etiketi_bul(text):\n",
    "    result = etiketleyici(text, candidate_labels=etiket_siniflari, multi_label=True)\n",
    "    # Eşik koyabiliriz, örn: skor > 0.3 olanlar\n",
    "    esik = 0.3\n",
    "    secilen_etiketler = [label for label, score in zip(result['labels'], result['scores']) if score > esik]\n",
    "    return secilen_etiketler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40cf3713-fb18-4d1e-b59d-3d6212b94dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.30.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.10.1 (from gradio)\n",
      "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (0.31.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.10-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gradio-client==1.10.1->gradio) (2024.6.1)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.10.1->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click<8.2,>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-5.30.0-py3-none-any.whl (54.2 MB)\n",
      "   ---------------------------------------- 0.0/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/54.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "   ---------------------------------------- 0.5/54.2 MB 294.2 kB/s eta 0:03:03\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 0.8/54.2 MB 191.7 kB/s eta 0:04:39\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.0/54.2 MB 164.5 kB/s eta 0:05:23\n",
      "    --------------------------------------- 1.3/54.2 MB 167.3 kB/s eta 0:05:16\n",
      "    --------------------------------------- 1.3/54.2 MB 167.3 kB/s eta 0:05:16\n",
      "    --------------------------------------- 1.3/54.2 MB 167.3 kB/s eta 0:05:16\n",
      "   - -------------------------------------- 1.6/54.2 MB 188.1 kB/s eta 0:04:40\n",
      "   - -------------------------------------- 1.6/54.2 MB 188.1 kB/s eta 0:04:40\n",
      "   - -------------------------------------- 1.6/54.2 MB 188.1 kB/s eta 0:04:40\n",
      "   - -------------------------------------- 1.8/54.2 MB 207.1 kB/s eta 0:04:13\n",
      "   - -------------------------------------- 1.8/54.2 MB 207.1 kB/s eta 0:04:13\n",
      "   - -------------------------------------- 1.8/54.2 MB 207.1 kB/s eta 0:04:13\n",
      "   - -------------------------------------- 2.1/54.2 MB 224.5 kB/s eta 0:03:52\n",
      "   - -------------------------------------- 2.1/54.2 MB 224.5 kB/s eta 0:03:52\n",
      "   - -------------------------------------- 2.4/54.2 MB 241.4 kB/s eta 0:03:35\n",
      "   - -------------------------------------- 2.4/54.2 MB 241.4 kB/s eta 0:03:35\n",
      "   - -------------------------------------- 2.6/54.2 MB 258.6 kB/s eta 0:03:20\n",
      "   - -------------------------------------- 2.6/54.2 MB 258.6 kB/s eta 0:03:20\n",
      "   -- ------------------------------------- 2.9/54.2 MB 275.5 kB/s eta 0:03:07\n",
      "   -- ------------------------------------- 2.9/54.2 MB 275.5 kB/s eta 0:03:07\n",
      "   -- ------------------------------------- 3.1/54.2 MB 292.5 kB/s eta 0:02:55\n",
      "   -- ------------------------------------- 3.4/54.2 MB 309.7 kB/s eta 0:02:44\n",
      "   -- ------------------------------------- 3.4/54.2 MB 309.7 kB/s eta 0:02:44\n",
      "   -- ------------------------------------- 3.7/54.2 MB 323.6 kB/s eta 0:02:37\n",
      "   -- ------------------------------------- 3.7/54.2 MB 323.6 kB/s eta 0:02:37\n",
      "   -- ------------------------------------- 3.7/54.2 MB 323.6 kB/s eta 0:02:37\n",
      "   -- ------------------------------------- 3.9/54.2 MB 328.9 kB/s eta 0:02:33\n",
      "   -- ------------------------------------- 3.9/54.2 MB 328.9 kB/s eta 0:02:33\n",
      "   -- ------------------------------------- 3.9/54.2 MB 328.9 kB/s eta 0:02:33\n",
      "   -- ------------------------------------- 3.9/54.2 MB 328.9 kB/s eta 0:02:33\n",
      "   -- ------------------------------------- 3.9/54.2 MB 328.9 kB/s eta 0:02:33\n",
      "   --- ------------------------------------ 4.2/54.2 MB 319.4 kB/s eta 0:02:37\n",
      "   --- ------------------------------------ 4.2/54.2 MB 319.4 kB/s eta 0:02:37\n",
      "   --- ------------------------------------ 4.2/54.2 MB 319.4 kB/s eta 0:02:37\n",
      "   --- ------------------------------------ 4.2/54.2 MB 319.4 kB/s eta 0:02:37\n",
      "   --- ------------------------------------ 4.5/54.2 MB 319.6 kB/s eta 0:02:36\n",
      "   --- ------------------------------------ 4.5/54.2 MB 319.6 kB/s eta 0:02:36\n",
      "   --- ------------------------------------ 4.5/54.2 MB 319.6 kB/s eta 0:02:36\n",
      "   --- ------------------------------------ 4.7/54.2 MB 325.2 kB/s eta 0:02:33\n",
      "   --- ------------------------------------ 4.7/54.2 MB 325.2 kB/s eta 0:02:33\n",
      "   --- ------------------------------------ 5.0/54.2 MB 333.3 kB/s eta 0:02:28\n",
      "   --- ------------------------------------ 5.0/54.2 MB 333.3 kB/s eta 0:02:28\n",
      "   --- ------------------------------------ 5.2/54.2 MB 342.0 kB/s eta 0:02:24\n",
      "   --- ------------------------------------ 5.2/54.2 MB 342.0 kB/s eta 0:02:24\n",
      "   --- ------------------------------------ 5.2/54.2 MB 342.0 kB/s eta 0:02:24\n",
      "   --- ------------------------------------ 5.2/54.2 MB 342.0 kB/s eta 0:02:24\n",
      "   --- ------------------------------------ 5.2/54.2 MB 342.0 kB/s eta 0:02:24\n",
      "   ---- ----------------------------------- 5.5/54.2 MB 337.9 kB/s eta 0:02:24\n",
      "   ---- ----------------------------------- 5.5/54.2 MB 337.9 kB/s eta 0:02:24\n",
      "   ---- ----------------------------------- 5.5/54.2 MB 337.9 kB/s eta 0:02:24\n",
      "   ---- ----------------------------------- 5.8/54.2 MB 341.7 kB/s eta 0:02:22\n",
      "   ---- ----------------------------------- 5.8/54.2 MB 341.7 kB/s eta 0:02:22\n",
      "   ---- ----------------------------------- 6.0/54.2 MB 347.9 kB/s eta 0:02:19\n",
      "   ---- ----------------------------------- 6.0/54.2 MB 347.9 kB/s eta 0:02:19\n",
      "   ---- ----------------------------------- 6.3/54.2 MB 355.0 kB/s eta 0:02:15\n",
      "   ---- ----------------------------------- 6.6/54.2 MB 362.7 kB/s eta 0:02:12\n",
      "   ---- ----------------------------------- 6.6/54.2 MB 362.7 kB/s eta 0:02:12\n",
      "   ----- ---------------------------------- 6.8/54.2 MB 371.2 kB/s eta 0:02:08\n",
      "   ----- ---------------------------------- 6.8/54.2 MB 371.2 kB/s eta 0:02:08\n",
      "   ----- ---------------------------------- 7.1/54.2 MB 378.0 kB/s eta 0:02:05\n",
      "   ----- ---------------------------------- 7.1/54.2 MB 378.0 kB/s eta 0:02:05\n",
      "   ----- ---------------------------------- 7.3/54.2 MB 384.2 kB/s eta 0:02:02\n",
      "   ----- ---------------------------------- 7.6/54.2 MB 391.1 kB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 7.6/54.2 MB 391.1 kB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 7.9/54.2 MB 397.8 kB/s eta 0:01:57\n",
      "   ------ --------------------------------- 8.1/54.2 MB 404.9 kB/s eta 0:01:54\n",
      "   ------ --------------------------------- 8.1/54.2 MB 404.9 kB/s eta 0:01:54\n",
      "   ------ --------------------------------- 8.4/54.2 MB 412.1 kB/s eta 0:01:52\n",
      "   ------ --------------------------------- 8.7/54.2 MB 420.1 kB/s eta 0:01:49\n",
      "   ------ --------------------------------- 8.9/54.2 MB 427.5 kB/s eta 0:01:46\n",
      "   ------ --------------------------------- 9.2/54.2 MB 435.4 kB/s eta 0:01:44\n",
      "   ------ --------------------------------- 9.2/54.2 MB 435.4 kB/s eta 0:01:44\n",
      "   ------ --------------------------------- 9.2/54.2 MB 435.4 kB/s eta 0:01:44\n",
      "   ------ --------------------------------- 9.4/54.2 MB 438.2 kB/s eta 0:01:43\n",
      "   ------- -------------------------------- 9.7/54.2 MB 446.1 kB/s eta 0:01:40\n",
      "   ------- -------------------------------- 10.0/54.2 MB 453.8 kB/s eta 0:01:38\n",
      "   ------- -------------------------------- 10.2/54.2 MB 461.6 kB/s eta 0:01:36\n",
      "   ------- -------------------------------- 10.5/54.2 MB 469.4 kB/s eta 0:01:34\n",
      "   ------- -------------------------------- 10.7/54.2 MB 476.9 kB/s eta 0:01:32\n",
      "   -------- ------------------------------- 11.3/54.2 MB 492.4 kB/s eta 0:01:28\n",
      "   -------- ------------------------------- 11.5/54.2 MB 500.3 kB/s eta 0:01:26\n",
      "   -------- ------------------------------- 11.8/54.2 MB 508.1 kB/s eta 0:01:24\n",
      "   -------- ------------------------------- 12.1/54.2 MB 515.7 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 12.3/54.2 MB 523.2 kB/s eta 0:01:20\n",
      "   --------- ------------------------------ 12.6/54.2 MB 530.6 kB/s eta 0:01:19\n",
      "   --------- ------------------------------ 12.8/54.2 MB 537.2 kB/s eta 0:01:17\n",
      "   --------- ------------------------------ 13.1/54.2 MB 543.0 kB/s eta 0:01:16\n",
      "   --------- ------------------------------ 13.4/54.2 MB 547.2 kB/s eta 0:01:15\n",
      "   --------- ------------------------------ 13.4/54.2 MB 547.2 kB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 13.6/54.2 MB 549.5 kB/s eta 0:01:14\n",
      "   ---------- ----------------------------- 13.6/54.2 MB 549.5 kB/s eta 0:01:14\n",
      "   ---------- ----------------------------- 13.9/54.2 MB 552.1 kB/s eta 0:01:13\n",
      "   ---------- ----------------------------- 14.2/54.2 MB 555.0 kB/s eta 0:01:13\n",
      "   ---------- ----------------------------- 14.2/54.2 MB 555.0 kB/s eta 0:01:13\n",
      "   ---------- ----------------------------- 14.4/54.2 MB 558.5 kB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 14.7/54.2 MB 562.3 kB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 14.7/54.2 MB 562.3 kB/s eta 0:01:11\n",
      "   ----------- ---------------------------- 14.9/54.2 MB 566.0 kB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 14.9/54.2 MB 566.0 kB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 15.2/54.2 MB 566.2 kB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 15.5/54.2 MB 570.7 kB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 15.7/54.2 MB 573.8 kB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 16.0/54.2 MB 578.2 kB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 16.0/54.2 MB 578.2 kB/s eta 0:01:07\n",
      "   ------------ --------------------------- 16.3/54.2 MB 581.5 kB/s eta 0:01:06\n",
      "   ------------ --------------------------- 16.5/54.2 MB 585.7 kB/s eta 0:01:05\n",
      "   ------------ --------------------------- 16.8/54.2 MB 589.8 kB/s eta 0:01:04\n",
      "   ------------ --------------------------- 17.0/54.2 MB 593.9 kB/s eta 0:01:03\n",
      "   ------------ --------------------------- 17.0/54.2 MB 593.9 kB/s eta 0:01:03\n",
      "   ------------ --------------------------- 17.3/54.2 MB 597.9 kB/s eta 0:01:02\n",
      "   ------------ --------------------------- 17.6/54.2 MB 600.8 kB/s eta 0:01:01\n",
      "   ------------ --------------------------- 17.6/54.2 MB 600.8 kB/s eta 0:01:01\n",
      "   ------------- -------------------------- 17.8/54.2 MB 603.4 kB/s eta 0:01:01\n",
      "   ------------- -------------------------- 18.1/54.2 MB 605.9 kB/s eta 0:01:00\n",
      "   ------------- -------------------------- 18.4/54.2 MB 609.0 kB/s eta 0:00:59\n",
      "   ------------- -------------------------- 18.4/54.2 MB 609.0 kB/s eta 0:00:59\n",
      "   ------------- -------------------------- 18.6/54.2 MB 612.3 kB/s eta 0:00:59\n",
      "   ------------- -------------------------- 18.9/54.2 MB 625.3 kB/s eta 0:00:57\n",
      "   -------------- ------------------------- 19.1/54.2 MB 628.9 kB/s eta 0:00:56\n",
      "   -------------- ------------------------- 19.4/54.2 MB 633.1 kB/s eta 0:00:55\n",
      "   -------------- ------------------------- 19.7/54.2 MB 669.2 kB/s eta 0:00:52\n",
      "   -------------- ------------------------- 19.7/54.2 MB 669.2 kB/s eta 0:00:52\n",
      "   -------------- ------------------------- 19.9/54.2 MB 670.4 kB/s eta 0:00:52\n",
      "   -------------- ------------------------- 19.9/54.2 MB 670.4 kB/s eta 0:00:52\n",
      "   -------------- ------------------------- 19.9/54.2 MB 670.4 kB/s eta 0:00:52\n",
      "   -------------- ------------------------- 20.2/54.2 MB 666.4 kB/s eta 0:00:51\n",
      "   -------------- ------------------------- 20.2/54.2 MB 666.4 kB/s eta 0:00:51\n",
      "   -------------- ------------------------- 20.2/54.2 MB 666.4 kB/s eta 0:00:51\n",
      "   --------------- ------------------------ 20.4/54.2 MB 658.1 kB/s eta 0:00:52\n",
      "   --------------- ------------------------ 20.4/54.2 MB 658.1 kB/s eta 0:00:52\n",
      "   --------------- ------------------------ 20.4/54.2 MB 658.1 kB/s eta 0:00:52\n",
      "   --------------- ------------------------ 20.7/54.2 MB 692.5 kB/s eta 0:00:49\n",
      "   --------------- ------------------------ 20.7/54.2 MB 692.5 kB/s eta 0:00:49\n",
      "   --------------- ------------------------ 21.0/54.2 MB 690.4 kB/s eta 0:00:49\n",
      "   --------------- ------------------------ 21.0/54.2 MB 690.4 kB/s eta 0:00:49\n",
      "   --------------- ------------------------ 21.2/54.2 MB 690.8 kB/s eta 0:00:48\n",
      "   --------------- ------------------------ 21.2/54.2 MB 690.8 kB/s eta 0:00:48\n",
      "   --------------- ------------------------ 21.5/54.2 MB 691.3 kB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 21.8/54.2 MB 692.5 kB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 21.8/54.2 MB 692.5 kB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 22.0/54.2 MB 721.1 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 22.3/54.2 MB 723.2 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 22.5/54.2 MB 725.5 kB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 22.8/54.2 MB 728.7 kB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 23.1/54.2 MB 731.4 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 23.1/54.2 MB 731.4 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 23.3/54.2 MB 734.8 kB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 23.6/54.2 MB 746.8 kB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 23.9/54.2 MB 750.5 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 24.4/54.2 MB 765.4 kB/s eta 0:00:39\n",
      "   ------------------ --------------------- 24.4/54.2 MB 765.4 kB/s eta 0:00:39\n",
      "   ------------------ --------------------- 24.6/54.2 MB 766.6 kB/s eta 0:00:39\n",
      "   ------------------ --------------------- 25.2/54.2 MB 781.2 kB/s eta 0:00:38\n",
      "   ------------------ --------------------- 25.4/54.2 MB 785.5 kB/s eta 0:00:37\n",
      "   ------------------ --------------------- 25.7/54.2 MB 789.7 kB/s eta 0:00:37\n",
      "   ------------------- -------------------- 26.0/54.2 MB 798.9 kB/s eta 0:00:36\n",
      "   ------------------- -------------------- 26.5/54.2 MB 807.7 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 26.7/54.2 MB 815.4 kB/s eta 0:00:34\n",
      "   ------------------- -------------------- 27.0/54.2 MB 819.9 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 27.3/54.2 MB 824.4 kB/s eta 0:00:33\n",
      "   -------------------- ------------------- 27.8/54.2 MB 836.2 kB/s eta 0:00:32\n",
      "   -------------------- ------------------- 28.0/54.2 MB 841.0 kB/s eta 0:00:32\n",
      "   --------------------- ------------------ 28.6/54.2 MB 850.7 kB/s eta 0:00:31\n",
      "   --------------------- ------------------ 28.8/54.2 MB 854.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 29.1/54.2 MB 858.1 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 29.6/54.2 MB 869.2 kB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 29.9/54.2 MB 873.8 kB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 30.4/54.2 MB 892.8 kB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 30.7/54.2 MB 897.4 kB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 31.2/54.2 MB 934.6 kB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 31.7/54.2 MB 944.1 kB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 32.0/54.2 MB 949.0 kB/s eta 0:00:24\n",
      "   ------------------------ --------------- 32.5/54.2 MB 958.7 kB/s eta 0:00:23\n",
      "   ------------------------ --------------- 32.8/54.2 MB 963.5 kB/s eta 0:00:23\n",
      "   ------------------------ --------------- 33.3/54.2 MB 973.5 kB/s eta 0:00:22\n",
      "   ------------------------ --------------- 33.8/54.2 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 34.1/54.2 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 34.6/54.2 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 35.1/54.2 MB 1.0 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 35.4/54.2 MB 1.0 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 35.9/54.2 MB 1.0 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 36.4/54.2 MB 1.1 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 37.0/54.2 MB 1.1 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 37.5/54.2 MB 1.1 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 38.0/54.2 MB 1.1 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 38.5/54.2 MB 1.1 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 39.1/54.2 MB 1.1 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 39.6/54.2 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 40.1/54.2 MB 1.2 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 40.6/54.2 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 41.4/54.2 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 41.9/54.2 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 42.2/54.2 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 42.5/54.2 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 43.0/54.2 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 43.3/54.2 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 43.5/54.2 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 43.8/54.2 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 44.0/54.2 MB 1.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 44.3/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 44.3/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 44.6/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 44.8/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 44.8/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 45.1/54.2 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 45.4/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 45.4/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 45.6/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 45.6/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 45.9/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 45.9/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 46.1/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 46.1/54.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 46.4/54.2 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 46.7/54.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 46.7/54.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 46.9/54.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 47.2/54.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 47.4/54.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 47.4/54.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 47.7/54.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 48.0/54.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 48.2/54.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 48.5/54.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 48.8/54.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 49.0/54.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 49.3/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 49.5/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 49.8/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 50.1/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 50.3/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 50.3/54.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 50.6/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 50.6/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 50.6/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 50.9/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 50.9/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 50.9/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 51.1/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 51.1/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 51.1/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 51.4/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 51.4/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 51.6/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 51.6/54.2 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 51.9/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 51.9/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 52.2/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 52.2/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 52.4/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 52.7/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 52.7/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  53.0/54.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  53.2/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  53.5/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  53.7/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "   ---------------------------------------  54.0/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  54.0/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  54.0/54.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 54.2/54.2 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.10-py3-none-win_amd64.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.7 MB 1.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/11.7 MB 1.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.3/11.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.6/11.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.1/11.7 MB 1.4 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.4/11.7 MB 1.5 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.1/11.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.4/11.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.7/11.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.7/11.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.9/11.7 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.2/11.7 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.5/11.7 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.5/11.7 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.7 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.7 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.7 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.7 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/11.7 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.7 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.0/11.7 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.0/11.7 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.7 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.7 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.8/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.8/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.1/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.1/11.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.3/11.7 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.3/11.7 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.6/11.7 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.6/11.7 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.9/11.7 MB 990.9 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.9/11.7 MB 990.9 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.1/11.7 MB 981.1 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.7 MB 977.7 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.7 MB 972.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.7 MB 972.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.7 MB 972.6 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 8.9/11.7 MB 956.2 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.9/11.7 MB 956.2 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.2/11.7 MB 929.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.2/11.7 MB 929.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.2/11.7 MB 929.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.4/11.7 MB 904.7 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.4/11.7 MB 904.7 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.4/11.7 MB 904.7 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.7/11.7 MB 867.8 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.7/11.7 MB 867.8 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.7/11.7 MB 867.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.0/11.7 MB 848.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.7 MB 848.1 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.7 MB 836.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.7 MB 836.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.5/11.7 MB 830.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.5/11.7 MB 830.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.7/11.7 MB 827.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.0/11.7 MB 826.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.7 MB 826.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.7 MB 829.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.7 MB 826.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.7 MB 826.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 818.0 kB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, groovy, ffmpy, aiofiles, uvicorn, starlette, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.30.0 gradio-client-1.10.1 groovy-0.1.2 orjson-3.10.18 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.4 uvicorn-0.34.2 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c461226-a0b6-45a6-acc8-8ef22af2b160",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\nNo module named 'transformers.models.ernie_m.configuration_ernie_m'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1510\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.ernie_m.configuration_ernie_m'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m BartForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Zero-shot etiketleyici\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Etiket listesi\u001b[39;00m\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mculture\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesign\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meconomics\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformal sciences\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhealth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanagement\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsychology\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreligion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocial issues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransportation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 906\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    907\u001b[0m         model,\n\u001b[0;32m    908\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    909\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    910\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    911\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    916\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    917\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:283\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    279\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a TensorFlow model (ending with `.h5`) but TensorFlow is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with PyTorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    285\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_pt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:540\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     _ = kwargs.pop(\"quantization_config\")\n\u001b[0;32m    531\u001b[0m config, kwargs = AutoConfig.from_pretrained(\n\u001b[0;32m    532\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    533\u001b[0m     return_unused_kwargs=True,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m     **kwargs,\n\u001b[0;32m    538\u001b[0m )\n\u001b[1;32m--> 540\u001b[0m # if torch_dtype=auto was passed here, ensure to pass it on\n\u001b[0;32m    541\u001b[0m if kwargs_orig.get(\"torch_dtype\", None) == \"auto\":\n\u001b[0;32m    542\u001b[0m     kwargs[\"torch_dtype\"] = \"auto\"\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:752\u001b[0m, in \u001b[0;36mkeys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_LazyAutoMapping\u001b[39;00m(OrderedDict):\n\u001b[0;32m    748\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m    \" A mapping config to object (model or tokenizer for instance) that will load keys and values when it is accessed.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;124;03m        - config_mapping: The map model type to config class\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m        - model_mapping: The map model type to model (or tokenizer) class\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_mapping, model_mapping):\n\u001b[0;32m    757\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping \u001b[38;5;241m=\u001b[39m config_mapping\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:748\u001b[0m, in \u001b[0;36m_load_attr_from_module\u001b[1;34m(self, model_type, attr)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_LazyAutoMapping\u001b[39;00m(OrderedDict):\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m    \" A mapping config to object (model or tokenizer for instance) that will load keys and values when it is accessed.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m        - config_mapping: The map model type to config class\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m        - model_mapping: The map model type to model (or tokenizer) class\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_mapping, model_mapping):\n\u001b[0;32m    757\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping \u001b[38;5;241m=\u001b[39m config_mapping\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:692\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[1;34m(module, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1500\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1500\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1501\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1512\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1513\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1515\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\nNo module named 'transformers.models.ernie_m.configuration_ernie_m'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, pipeline\n",
    "import torch\n",
    "\n",
    "# Cihaz seçimi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Özetleme modeli ve tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Zero-shot etiketleyici\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Etiket listesi\n",
    "labels = [\n",
    "    \"art\", \"business\", \"culture\", \"design\", \"economics\",\n",
    "    \"education\", \"media\", \"environment\", \"formal sciences\", \"health\", \"history\", \"law\",\n",
    "    \"management\", \"music\", \"psychology\", \"religion\",\n",
    "    \"social issues\", \"transportation\"\n",
    "]\n",
    "\n",
    "def ozetle(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def etiketle(text):\n",
    "    result = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    top_labels = result[\"labels\"][:3]  # En güçlü ilk 3 etiketi al\n",
    "    return \", \".join(top_labels)\n",
    "\n",
    "def ozete_ve_etikete(text):\n",
    "    summary = ozetle(text)\n",
    "    labels_str = etiketle(summary)  # Özeti etiketle, orijinal metin değil\n",
    "    return summary, labels_str\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=ozete_ve_etikete,\n",
    "    inputs=gr.Textbox(lines=10, placeholder=\"Metni buraya yapıştırın...\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Özet\"),\n",
    "        gr.Textbox(label=\"Tahmini Etiketler\")\n",
    "    ],\n",
    "    title=\"Metin Özetleme ve Etiketleme\",\n",
    "    description=\"Bir metin girin, özetini ve etiketlerini alın.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f2d6ce-77a0-4524-aa56-df142d9588ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan aygıt: GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ essay_100_summary.txt → religion\n",
      "✔ essay_101_summary.txt → culture\n",
      "✔ essay_102_summary.txt → business\n",
      "✔ essay_103_summary.txt → health\n",
      "✔ essay_104_summary.txt → business\n",
      "✔ essay_105_summary.txt → psyhology\n",
      "✔ essay_106_summary.txt → media\n",
      "✔ essay_107_summary.txt → law\n",
      "✔ essay_108_summary.txt → culture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ essay_109_summary.txt → environment\n",
      "✔ essay_10_summary.txt → environment\n",
      "✔ essay_110_summary.txt → health\n",
      "✔ essay_111_summary.txt → health\n",
      "✔ essay_112_summary.txt → media\n",
      "✔ essay_113_summary.txt → natural scicences\n",
      "✔ essay_114_summary.txt → environment\n",
      "✔ essay_115_summary.txt → psyhology\n",
      "✔ essay_116_summary.txt → culture\n",
      "✔ essay_117_summary.txt → social issues\n",
      "✔ essay_118_summary.txt → social issues\n",
      "✔ essay_119_summary.txt → health\n",
      "✔ essay_11_summary.txt → transportation\n",
      "✔ essay_120_summary.txt → business\n",
      "✔ essay_121_summary.txt → culture\n",
      "✔ essay_122_summary.txt → media\n",
      "✔ essay_123_summary.txt → health\n",
      "✔ essay_124_summary.txt → history\n",
      "✔ essay_125_summary.txt → environment\n",
      "✔ essay_126_summary.txt → business\n",
      "✔ essay_127_summary.txt → psyhology\n",
      "✔ essay_128_summary.txt → social issues\n",
      "✔ essay_129_summary.txt → religion\n",
      "✔ essay_12_summary.txt → economics\n",
      "✔ essay_130_summary.txt → social issues\n",
      "✔ essay_131_summary.txt → media\n",
      "✔ essay_132_summary.txt → history\n",
      "✔ essay_133_summary.txt → environment\n",
      "✔ essay_134_summary.txt → psyhology\n",
      "✔ essay_135_summary.txt → health\n",
      "✔ essay_136_summary.txt → music\n",
      "✔ essay_137_summary.txt → history\n",
      "✔ essay_138_summary.txt → business\n",
      "✔ essay_139_summary.txt → business\n",
      "✔ essay_13_summary.txt → media\n",
      "✔ essay_140_summary.txt → social issues\n",
      "✔ essay_141_summary.txt → formal sciences\n",
      "✔ essay_142_summary.txt → health\n",
      "✔ essay_143_summary.txt → media\n",
      "✔ essay_144_summary.txt → business\n",
      "✔ essay_145_summary.txt → business\n",
      "✔ essay_146_summary.txt → business\n",
      "✔ essay_147_summary.txt → business\n",
      "✔ essay_148_summary.txt → psyhology\n",
      "✔ essay_149_summary.txt → health\n",
      "✔ essay_14_summary.txt → art\n",
      "✔ essay_150_summary.txt → design\n",
      "✔ essay_151_summary.txt → health\n",
      "✔ essay_152_summary.txt → business\n",
      "✔ essay_153_summary.txt → social issues\n",
      "✔ essay_154_summary.txt → health\n",
      "✔ essay_155_summary.txt → health\n",
      "✔ essay_156_summary.txt → music\n",
      "✔ essay_157_summary.txt → media\n",
      "✔ essay_158_summary.txt → health\n",
      "✔ essay_159_summary.txt → health\n",
      "✔ essay_15_summary.txt → media\n",
      "✔ essay_160_summary.txt → design\n",
      "✔ essay_161_summary.txt → history\n",
      "✔ essay_162_summary.txt → history\n",
      "✔ essay_163_summary.txt → media\n",
      "✔ essay_164_summary.txt → business\n",
      "✔ essay_165_summary.txt → transportation\n",
      "✔ essay_166_summary.txt → media\n",
      "✔ essay_167_summary.txt → business\n",
      "✔ essay_168_summary.txt → formal sciences\n",
      "✔ essay_169_summary.txt → media\n",
      "✔ essay_16_summary.txt → law\n",
      "✔ essay_170_summary.txt → art\n",
      "✔ essay_171_summary.txt → health\n",
      "✔ essay_172_summary.txt → health\n",
      "✔ essay_173_summary.txt → environment\n",
      "✔ essay_174_summary.txt → culture\n",
      "✔ essay_175_summary.txt → media\n",
      "✔ essay_176_summary.txt → religion\n",
      "✔ essay_177_summary.txt → health\n",
      "✔ essay_178_summary.txt → psyhology\n",
      "✔ essay_179_summary.txt → environment\n",
      "✔ essay_17_summary.txt → health\n",
      "✔ essay_180_summary.txt → environment\n",
      "✔ essay_181_summary.txt → business\n",
      "✔ essay_182_summary.txt → health\n",
      "✔ essay_183_summary.txt → history\n",
      "✔ essay_184_summary.txt → health\n",
      "✔ essay_185_summary.txt → environment\n",
      "✔ essay_186_summary.txt → health\n",
      "✔ essay_187_summary.txt → health\n",
      "✔ essay_188_summary.txt → health\n",
      "✔ essay_189_summary.txt → health\n",
      "✔ essay_18_summary.txt → social issues\n",
      "✔ essay_190_summary.txt → law\n",
      "✔ essay_191_summary.txt → psyhology\n",
      "✔ essay_192_summary.txt → history\n",
      "✔ essay_193_summary.txt → social issues\n",
      "✔ essay_194_summary.txt → health\n",
      "✔ essay_195_summary.txt → environment\n",
      "✔ essay_196_summary.txt → design\n",
      "✔ essay_197_summary.txt → environment\n",
      "✔ essay_198_summary.txt → natural scicences\n",
      "✔ essay_199_summary.txt → health\n",
      "✔ essay_19_summary.txt → environment\n",
      "✔ essay_1_summary.txt → media\n",
      "✔ essay_200_summary.txt → environment\n",
      "✔ essay_201_summary.txt → business\n",
      "✔ essay_202_summary.txt → sociology\n",
      "✔ essay_203_summary.txt → warfare\n",
      "✔ essay_204_summary.txt → health\n",
      "✔ essay_205_summary.txt → health\n",
      "✔ essay_206_summary.txt → health\n",
      "✔ essay_207_summary.txt → social issues\n",
      "✔ essay_208_summary.txt → law\n",
      "✔ essay_209_summary.txt → law\n",
      "✔ essay_20_summary.txt → media\n",
      "✔ essay_210_summary.txt → formal sciences\n",
      "✔ essay_211_summary.txt → history\n",
      "✔ essay_212_summary.txt → social issues\n",
      "✔ essay_213_summary.txt → psyhology\n",
      "✔ essay_214_summary.txt → culture\n",
      "✔ essay_215_summary.txt → culture\n",
      "✔ essay_216_summary.txt → social issues\n",
      "✔ essay_217_summary.txt → culture\n",
      "✔ essay_218_summary.txt → culture\n",
      "✔ essay_219_summary.txt → culture\n",
      "✔ essay_21_summary.txt → design\n",
      "✔ essay_220_summary.txt → social issues\n",
      "✔ essay_221_summary.txt → natural scicences\n",
      "✔ essay_222_summary.txt → transportation\n",
      "✔ essay_223_summary.txt → psyhology\n",
      "✔ essay_224_summary.txt → media\n",
      "✔ essay_225_summary.txt → natural scicences\n",
      "✔ essay_226_summary.txt → health\n",
      "✔ essay_227_summary.txt → natural scicences\n",
      "✔ essay_228_summary.txt → culture\n",
      "✔ essay_229_summary.txt → business\n",
      "✔ essay_22_summary.txt → health\n",
      "✔ essay_230_summary.txt → management\n",
      "✔ essay_231_summary.txt → health\n",
      "✔ essay_232_summary.txt → culture\n",
      "✔ essay_233_summary.txt → media\n",
      "✔ essay_234_summary.txt → natural scicences\n",
      "✔ essay_235_summary.txt → psyhology\n",
      "✔ essay_236_summary.txt → health\n",
      "✔ essay_237_summary.txt → media\n",
      "✔ essay_238_summary.txt → business\n",
      "✔ essay_239_summary.txt → health\n",
      "✔ essay_23_summary.txt → art\n",
      "✔ essay_240_summary.txt → health\n",
      "✔ essay_241_summary.txt → health\n",
      "✔ essay_242_summary.txt → health\n",
      "✔ essay_243_summary.txt → business\n",
      "✔ essay_244_summary.txt → natural scicences\n",
      "✔ essay_245_summary.txt → business\n",
      "✔ essay_246_summary.txt → religion\n",
      "✔ essay_247_summary.txt → law\n",
      "✔ essay_248_summary.txt → religion\n",
      "✔ essay_249_summary.txt → transportation\n",
      "✔ essay_24_summary.txt → education\n",
      "✔ essay_250_summary.txt → social issues\n",
      "✔ essay_251_summary.txt → religion\n",
      "✔ essay_252_summary.txt → health\n",
      "✔ essay_253_summary.txt → art\n",
      "✔ essay_254_summary.txt → psyhology\n",
      "✔ essay_255_summary.txt → culture\n",
      "✔ essay_256_summary.txt → business\n",
      "✔ essay_257_summary.txt → psyhology\n",
      "✔ essay_258_summary.txt → law\n",
      "✔ essay_259_summary.txt → history\n",
      "✔ essay_25_summary.txt → education\n",
      "✔ essay_260_summary.txt → law\n",
      "✔ essay_261_summary.txt → business\n",
      "✔ essay_262_summary.txt → marketing\n",
      "✔ essay_263_summary.txt → law\n",
      "✔ essay_264_summary.txt → environment\n",
      "✔ essay_265_summary.txt → environment\n",
      "✔ essay_266_summary.txt → management\n",
      "✔ essay_267_summary.txt → social issues\n",
      "✔ essay_268_summary.txt → health\n",
      "✔ essay_269_summary.txt → health\n",
      "✔ essay_26_summary.txt → business\n",
      "✔ essay_270_summary.txt → culture\n",
      "✔ essay_271_summary.txt → marketing\n",
      "✔ essay_272_summary.txt → culture\n",
      "✔ essay_273_summary.txt → health\n",
      "✔ essay_274_summary.txt → health\n",
      "✔ essay_275_summary.txt → social issues\n",
      "✔ essay_276_summary.txt → natural scicences\n",
      "✔ essay_277_summary.txt → business\n",
      "✔ essay_278_summary.txt → psyhology\n",
      "✔ essay_279_summary.txt → social issues\n",
      "✔ essay_27_summary.txt → art\n",
      "✔ essay_280_summary.txt → health\n",
      "✔ essay_281_summary.txt → media\n",
      "✔ essay_282_summary.txt → health\n",
      "✔ essay_283_summary.txt → environment\n",
      "✔ essay_284_summary.txt → health\n",
      "✔ essay_285_summary.txt → economics\n",
      "✔ essay_286_summary.txt → media\n",
      "✔ essay_287_summary.txt → education\n",
      "✔ essay_288_summary.txt → media\n",
      "✔ essay_289_summary.txt → transportation\n",
      "✔ essay_28_summary.txt → media\n",
      "✔ essay_290_summary.txt → media\n",
      "✔ essay_291_summary.txt → management\n",
      "✔ essay_292_summary.txt → art\n",
      "✔ essay_293_summary.txt → design\n",
      "✔ essay_294_summary.txt → health\n",
      "✔ essay_295_summary.txt → art\n",
      "✔ essay_296_summary.txt → health\n",
      "✔ essay_297_summary.txt → law\n",
      "✔ essay_298_summary.txt → health\n",
      "✔ essay_299_summary.txt → social issues\n",
      "✔ essay_29_summary.txt → social issues\n",
      "✔ essay_2_summary.txt → media\n",
      "✔ essay_300_summary.txt → marketing\n",
      "✔ essay_30_summary.txt → business\n",
      "✔ essay_31_summary.txt → music\n",
      "✔ essay_32_summary.txt → business\n",
      "✔ essay_33_summary.txt → environment\n",
      "✔ essay_34_summary.txt → law\n",
      "✔ essay_35_summary.txt → health\n",
      "✔ essay_36_summary.txt → social issues\n",
      "✔ essay_37_summary.txt → health\n",
      "✔ essay_38_summary.txt → social issues\n",
      "✔ essay_39_summary.txt → social issues\n",
      "✔ essay_3_summary.txt → media\n",
      "✔ essay_40_summary.txt → business\n",
      "✔ essay_41_summary.txt → religion\n",
      "✔ essay_42_summary.txt → transportation\n",
      "✔ essay_43_summary.txt → education\n",
      "✔ essay_44_summary.txt → social issues\n",
      "✔ essay_45_summary.txt → health\n",
      "✔ essay_46_summary.txt → social issues\n",
      "✔ essay_47_summary.txt → environment\n",
      "✔ essay_48_summary.txt → culture\n",
      "✔ essay_49_summary.txt → culture\n",
      "✔ essay_4_summary.txt → environment\n",
      "✔ essay_50_summary.txt → management\n",
      "✔ essay_51_summary.txt → law\n",
      "✔ essay_52_summary.txt → social issues\n",
      "✔ essay_53_summary.txt → psyhology\n",
      "✔ essay_54_summary.txt → media\n",
      "✔ essay_55_summary.txt → health\n",
      "✔ essay_56_summary.txt → business\n",
      "✔ essay_57_summary.txt → natural scicences\n",
      "✔ essay_58_summary.txt → business\n",
      "✔ essay_59_summary.txt → music\n",
      "✔ essay_5_summary.txt → business\n",
      "✔ essay_60_summary.txt → social issues\n",
      "✔ essay_61_summary.txt → health\n",
      "✔ essay_62_summary.txt → social issues\n",
      "✔ essay_63_summary.txt → tourism\n",
      "✔ essay_64_summary.txt → psyhology\n",
      "✔ essay_65_summary.txt → natural scicences\n",
      "✔ essay_66_summary.txt → business\n",
      "✔ essay_67_summary.txt → social issues\n",
      "✔ essay_68_summary.txt → environment\n",
      "✔ essay_69_summary.txt → business\n",
      "✔ essay_6_summary.txt → health\n",
      "✔ essay_70_summary.txt → music\n",
      "✔ essay_71_summary.txt → environment\n",
      "✔ essay_72_summary.txt → health\n",
      "✔ essay_73_summary.txt → art\n",
      "✔ essay_74_summary.txt → art\n",
      "✔ essay_75_summary.txt → formal sciences\n",
      "✔ essay_76_summary.txt → art\n",
      "✔ essay_77_summary.txt → media\n",
      "✔ essay_78_summary.txt → culture\n",
      "✔ essay_79_summary.txt → health\n",
      "✔ essay_7_summary.txt → media\n",
      "✔ essay_80_summary.txt → social issues\n",
      "✔ essay_81_summary.txt → design\n",
      "✔ essay_82_summary.txt → natural scicences\n",
      "✔ essay_83_summary.txt → culture\n",
      "✔ essay_84_summary.txt → psyhology\n",
      "✔ essay_85_summary.txt → culture\n",
      "✔ essay_86_summary.txt → business\n",
      "✔ essay_87_summary.txt → media\n",
      "✔ essay_88_summary.txt → sports\n",
      "✔ essay_89_summary.txt → environment\n",
      "✔ essay_8_summary.txt → social issues\n",
      "✔ essay_90_summary.txt → business\n",
      "✔ essay_91_summary.txt → media\n",
      "✔ essay_92_summary.txt → health\n",
      "✔ essay_93_summary.txt → art\n",
      "✔ essay_94_summary.txt → media\n",
      "✔ essay_95_summary.txt → formal sciences\n",
      "✔ essay_96_summary.txt → business\n",
      "✔ essay_97_summary.txt → marketing\n",
      "✔ essay_98_summary.txt → business\n",
      "✔ essay_99_summary.txt → law\n",
      "✔ essay_9_summary.txt → psyhology\n",
      "\n",
      "✅ Kayıt tamamlandı: summary_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# GPU kontrolü\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Kullanılan aygıt:\", \"GPU\" if device == 0 else \"CPU\")\n",
    "\n",
    "# Zero-shot sınıflandırıcıyı yükle\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Etiket listesi\n",
    "labels = [\"art\", \"business\", \"cinematography\", \"culture\", \"design\", \"diet&nutrition\", \"economics\", \"education\", \"media\", \"environment\",\n",
    "          \"formal sciences\", \"health\", \"history\", \"law\", \"management\", \"marketing\", \"music\", \"natural scicences\", \"psyhology\", \"religion\",\n",
    "          \"social issues\", \"sociology\", \"sports\", \"engineering\", \"tourism\", \"transportation\", \"warfare\"]\n",
    "\n",
    "# Özetlerin bulunduğu klasör\n",
    "summary_folder = \"C:/Users/Lenovo/Desktop/Ozetler_hug\"\n",
    "\n",
    "# Özet + kategori listesi\n",
    "data = []\n",
    "\n",
    "# Her özet dosyasını işle\n",
    "for filename in os.listdir(summary_folder):\n",
    "    if filename.endswith(\"_summary.txt\"):\n",
    "        file_path = os.path.join(summary_folder, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            summary = f.read()\n",
    "\n",
    "        result = classifier(summary, labels)\n",
    "        best_label = result[\"labels\"][0]\n",
    "\n",
    "        data.append({\n",
    "            \"essay\": filename.replace(\"_summary.txt\", \".txt\"),\n",
    "            \"summary\": summary,\n",
    "            \"label\": best_label\n",
    "        })\n",
    "\n",
    "        print(f\"✔ {filename} → {best_label}\")\n",
    "\n",
    "# DataFrame olarak kaydet\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"/summary_with_labels.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"\\n✅ Kayıt tamamlandı: summary_with_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27e7256a-f6e9-455f-8005-7e73b414cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed02ac8d-7225-497b-b9c2-1a4d2750ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 35.737s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x12db366b320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "    def test_ozetle(self):\n",
    "        metin = \"This is a test input for the summarizer.\"\n",
    "        sonuc = ozetle(metin)\n",
    "        self.assertIsInstance(sonuc, str)\n",
    "        self.assertGreater(len(sonuc), 10)\n",
    "\n",
    "    def test_etiketle(self):\n",
    "        metin = \"Pollution affects the environment and public health.\"\n",
    "        sonuc = etiketle(metin)\n",
    "        self.assertIsInstance(sonuc, str)\n",
    "        self.assertIn(\"environment\", sonuc)\n",
    "\n",
    "unittest.main(argv=[''], exit=False)  # Jupyter için exit=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7acfb5d-5c63-4347-a0a4-03492d69579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ozete_ve_etikete_integration():\n",
    "    text = \"The stock market experienced a sharp decline due to inflation concerns.\"\n",
    "    summary, labels = ozete_ve_etikete(text)\n",
    "    assert isinstance(summary, str)\n",
    "    assert isinstance(labels, str)\n",
    "    assert len(summary) > 10\n",
    "    assert any(label in labels for label in [\"economics\", \"business\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d38eb57-cc55-4b33-9714-c67cf1a65417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_ozete_ve_etikete_integration (__main__.TestModel.test_ozete_ve_etikete_integration) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 43.766s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özet: The stock market experienced a sharp decline due to inflation concerns. Inflation concerns led to a sharp drop in the stock market. The fall was caused by a sharp fall in the value of the dollar. The decline was due to a decline in the dollar's value against other currencies.\n",
      "Etiketler: economics, business, management\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "    def test_ozete_ve_etikete_integration(self):\n",
    "        metin = \"The stock market experienced a sharp decline due to inflation concerns.\"\n",
    "        summary, labels = ozete_ve_etikete(metin)\n",
    "        print(\"Özet:\", summary)\n",
    "        print(\"Etiketler:\", labels)\n",
    "        self.assertIsInstance(summary, str)\n",
    "        self.assertIsInstance(labels, str)\n",
    "        self.assertGreater(len(summary), 10)\n",
    "        self.assertTrue(any(label in labels for label in [\"economics\", \"business\"]))\n",
    "\n",
    "# Çıktıların görünmesi için testleri bu şekilde çalıştır:\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestModel)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
